{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b8838e-79d2-4e45-8693-31729bd39c3f",
   "metadata": {},
   "source": [
    "# Advanced Ollama Features Tutorial: 🛠️ Tool Usage 🛠️\n",
    "\n",
    "In this notebook, we'll explore a powerful feature of Ollama that allows us to equip AI with using custom functions\n",
    "\n",
    "## 0. Import libraries + Start Ollama server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0295e6e-a623-4cbc-8f1d-3a81e2fa0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import psutil\n",
    "from ollama import ChatResponse, chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623a29e6-5461-487b-bc3c-69ab44b1adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "def is_port_in_use(port: int = 11434) -> bool:\n",
    "    \"\"\"Check if the Ollama port is already in use\"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        return s.connect_ex(('localhost', port)) == 0\n",
    "\n",
    "def is_ollama_running() -> bool:\n",
    "    \"\"\"Check if Ollama process is running\"\"\"\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        try:\n",
    "            if proc.info['name'] == 'ollama':\n",
    "                return True\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "def ensure_ollama_server():\n",
    "    \"\"\"\n",
    "    Ensures that an Ollama server is running.\n",
    "    Returns the process object if a new server was started, None if server was already running.\n",
    "    \"\"\"\n",
    "    # First check if the server is already running\n",
    "    if is_port_in_use() or is_ollama_running():\n",
    "        print(\"✅ Ollama server is already running!\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Start the Ollama server\n",
    "        print(\"🚀 Starting Ollama server...\")\n",
    "        proc = subprocess.Popen(\n",
    "            [\"ollama\", \"serve\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            start_new_session=True\n",
    "        )\n",
    "        \n",
    "        # Wait for the server to start (max 10 seconds)\n",
    "        for _ in range(10):\n",
    "            if is_port_in_use():\n",
    "                print(f\"✅ Ollama server started successfully (PID: {proc.pid})\")\n",
    "                return proc\n",
    "            time.sleep(1)\n",
    "            \n",
    "        raise TimeoutError(\"Server didn't start within 10 seconds\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error starting Ollama server: {e}\")\n",
    "        if 'proc' in locals():\n",
    "            proc.terminate()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dcc3a0-c3c3-4a4f-95dd-7a0749675249",
   "metadata": {},
   "source": [
    "#### Start the ollama server and list ollama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f936bc-4130-474d-b848-fae111e22c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Ollama server...\n",
      "✅ Ollama server started successfully (PID: 2268460)\n"
     ]
    }
   ],
   "source": [
    "# Start the server if it's not already running\n",
    "ollama_process = ensure_ollama_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74293bc6-af13-4a73-a9a0-56d14547b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      ID              SIZE      MODIFIED   \n",
      "llama3.2-vision:latest    6f2f9757ae97    7.8 GB    3 days ago    \n",
      "llama3.1:latest           46e0c10c039e    4.9 GB    3 days ago    \n",
      "llama3.2:1b               baf6a787fdff    1.3 GB    4 days ago    \n",
      "llava:latest              8dd30f6b0cb1    4.7 GB    5 days ago    \n",
      "qwen3:0.6b                7df6b6e09427    522 MB    5 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama ls\n",
    "# If you need to pull models, uncomment the following:\n",
    "# !ollama pull phi4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f62324-dc49-4ffb-83dc-286d1ceeaba8",
   "metadata": {},
   "source": [
    "## 1. Tool Use: Making AI Use Custom Functions 🛠️\n",
    "\n",
    "One of the coolest features of advanced AI models is their ability to use tools - custom functions that we define. This allows the AI to perform actual calculations or actions.\n",
    "\n",
    "In this example, we'll create two simple math functions and let the AI use them to solve problems. Here's how it works:\n",
    "\n",
    "1. We define some functions (tools) that the AI can use\n",
    "2. We tell the AI about these tools\n",
    "3. The AI decides when and how to use them\n",
    "\n",
    "Let's try it out! We will first create two tools we want the LLM to use rather than think about: addition and substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8601c250-3f00-423a-a676-1c62b5117eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "  \"\"\"\n",
    "  Add two numbers\n",
    "  Args:\n",
    "    a (int): The first number\n",
    "    b (int): The second number\n",
    "  Returns:\n",
    "    int: The sum of the two numbers\n",
    "  \"\"\"\n",
    "  # The cast is necessary as returned tool call arguments don't always conform exactly to schema\n",
    "  # E.g. this would prevent \"what is 30 + 12\" to produce '3012' instead of 42\n",
    "  return int(a) + int(b)\n",
    "\n",
    "def subtract_two_numbers(a: int, b: int) -> int:\n",
    "  \"\"\"\n",
    "  Subtract two numbers\n",
    "  \"\"\"\n",
    "  # The cast is necessary as returned tool call arguments don't always conform exactly to schema\n",
    "  return int(a) - int(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29407d92-c6ad-493b-a5a8-1c70bbfa0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now will create a dictionary that has the two functions we implemented\n",
    "# This is to map tool names → Python callables\n",
    "available_functions = {\n",
    "  'add_two_numbers': add_two_numbers,\n",
    "  'subtract_two_numbers': subtract_two_numbers,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a02767-6181-468f-8eb7-12275ff03c91",
   "metadata": {},
   "source": [
    "### This step is optional but good practice to implement.\n",
    "\n",
    "Tools can be manually defined by schema's which can be passed into chat (i.e the context of the LLM). This allows the LLM to have more knowledge on a tool's description, input arguments, return arguments, etc.\n",
    "\n",
    "For now we will only create a schema for the substract tool to show that this is optional and not mandatory when using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3586bdd4-0c8d-4283-a6f8-d85cf0b24e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools can still be manually defined and passed into chat\n",
    "subtract_two_numbers_tool = {\n",
    "  'type': 'function',\n",
    "  'function': {\n",
    "    'name': 'subtract_two_numbers',                 # Has to match exactly the syntax for the actual python subtract_two_numbers function\n",
    "    'description': 'Subtract two numbers',\n",
    "    'parameters': {\n",
    "      'type': 'object',\n",
    "      'required': ['a', 'b'],\n",
    "      'properties': {\n",
    "        'a': {'type': 'integer', 'description': 'The first number'},\n",
    "        'b': {'type': 'integer', 'description': 'The second number'},\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be50658-9f2e-4256-a653-4d70ec9bddc6",
   "metadata": {},
   "source": [
    "#### Let's now come up with a good prompt in which the LLM will be using the addition/substraction tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2062a5-79d9-4284-be60-5c2a676411ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is three plus one?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'What is three plus one?'     # Prompt to give to the LLM\n",
    "    }\n",
    "]\n",
    "print('Prompt:', messages[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1d0d4-6193-4534-a5fb-05177a63d59f",
   "metadata": {},
   "source": [
    "#### Now we can run the LLM to get a response but we include a list of the 2 available tools we implemented.\n",
    "\n",
    "Note that we use the actual python function for add_two_numbers whereas the schema for subtract_two_numbers_tool. This is done to show you the 2 ways to do tool usage with LLM's in ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f45f688b-b2be-4c80-b0e7-37dfedc55c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response: ChatResponse = chat(\n",
    "  'llama3.1',\n",
    "  messages=messages,\n",
    "  tools=[add_two_numbers, subtract_two_numbers_tool],  # Note: we use the actual python function for addition but the schema for subtract_two_numbers_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf3fa7b-5660-49cb-bf9d-8ca18573a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: add_two_numbers\n",
      "Arguments: {'a': 3, 'b': 1}\n",
      "Function output: 4\n",
      "Final response: The answer to the equation 3 + 1 is 4.\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "  # There may be multiple tool calls in the response\n",
    "  for tool in response.message.tool_calls:\n",
    "    # Ensure the function is available, and then call it\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print('Calling function:', tool.function.name)\n",
    "      print('Arguments:', tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print('Function output:', output)\n",
    "    else:\n",
    "      print('Function', tool.function.name, 'not found')\n",
    "\n",
    "  # Add the function response to messages for the model to use\n",
    "  messages.append(response.message)\n",
    "  messages.append({'role': 'tool', 'content': str(output), 'name': tool.function.name})\n",
    "\n",
    "  # Get final response from model with function outputs\n",
    "  final_response = chat('llama3.1', messages=messages)\n",
    "  print('Final response:', final_response.message.content)\n",
    "else:\n",
    "  print('No tool calls returned from model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e853c2-47be-4e9f-b5c4-607ea9c7fdb7",
   "metadata": {},
   "source": [
    "### Now let's try a prompt in which the LLM will try to use both tools (i.e both addition and substraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d859e38-80b3-4aff-a7ea-078d48aed2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is three plus one? What is four minus two\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'What is three plus one? What is four minus two'     # Prompt to give to the LLM\n",
    "    }\n",
    "]\n",
    "print('Prompt:', messages[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f95c682-8d33-4d73-9f7c-436c582a22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response: ChatResponse = chat(\n",
    "  'llama3.1',\n",
    "  messages=messages,\n",
    "  tools=[add_two_numbers, subtract_two_numbers_tool],  # Note: we use the actual python function for addition but the schema for subtract_two_numbers_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30b56ff9-2725-4483-abc1-bfbdfd524487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: add_two_numbers\n",
      "Arguments: {'a': 3, 'b': 1}\n",
      "Function output: 4\n",
      "Calling function: subtract_two_numbers\n",
      "Arguments: {'a': 4, 'b': 2}\n",
      "Function output: 2\n",
      "Final response: The answer to the first question is 4. The answer to the second question is 2.\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "  # There may be multiple tool calls in the response\n",
    "  for tool in response.message.tool_calls:\n",
    "    # Ensure the function is available, and then call it\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print('Calling function:', tool.function.name)\n",
    "      print('Arguments:', tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print('Function output:', output)\n",
    "    else:\n",
    "      print('Function', tool.function.name, 'not found')\n",
    "\n",
    "  # Add the function response to messages for the model to use\n",
    "  messages.append(response.message)\n",
    "  messages.append({'role': 'tool', 'content': str(output), 'name': tool.function.name})\n",
    "\n",
    "  # Get final response from model with function outputs\n",
    "  final_response = chat('llama3.1', messages=messages)\n",
    "  print('Final response:', final_response.message.content)\n",
    "else:\n",
    "  print('No tool calls returned from model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3ac0d-2cba-49ad-bf8b-e75691db5611",
   "metadata": {},
   "source": [
    "## Exercise 1: Conversion of Fahrenheit to Celsius -- with no Schema\n",
    "\n",
    "Now it is your turn to try and implement tools for other tasks.\n",
    "The first tools you have to implement are tools to convert Fahrenheit to Celsius (and vice-versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6e4adda-416a-4939-b65d-2123802f3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(fahrenheit: float) -> float:\n",
    "  \"\"\"\n",
    "  Convert Fahrenheit to Celsius.\n",
    "\n",
    "  Args:\n",
    "    fahrenheit (float): Temperature in Fahrenheit.\n",
    "\n",
    "  Returns:\n",
    "    float: Temperature in Celsius.\n",
    "  \"\"\"\n",
    "  # Cast to float in case the model gives back a string\n",
    "  return (float(fahrenheit) - 32.0) * 5.0 / 9.0\n",
    "\n",
    "\n",
    "def celsius_to_fahrenheit(celsius: float) -> float:\n",
    "  \"\"\"\n",
    "  Convert Celsius to Fahrenheit.\n",
    "\n",
    "  Args:\n",
    "    celsius (float): Temperature in Celsius.\n",
    "\n",
    "  Returns:\n",
    "    float: Temperature in Fahrenheit.\n",
    "  \"\"\"\n",
    "  return float(celsius) * 9.0 / 5.0 + 32.0\n",
    "\n",
    "# Map tool names → Python callables\n",
    "available_functions = {\n",
    "  \"fahrenheit_to_celsius\": fahrenheit_to_celsius,\n",
    "  \"celsius_to_fahrenheit\": celsius_to_fahrenheit,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6602dbb-72ab-454e-ba87-87b7eb564bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: It's 75°F outside. What is that in Celsius?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"It's 75°F outside. What is that in Celsius?\"\n",
    "  }\n",
    "]\n",
    "\n",
    "print(\"Prompt:\", messages[0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0b256c5-0d5e-4d6d-a8dc-9a25b7cdc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response: ChatResponse = chat(\n",
    "  \"llama3.1\",\n",
    "  messages=messages,\n",
    "  tools=[fahrenheit_to_celsius, celsius_to_fahrenheit],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0771152-6376-4d4a-9ebd-d7ab4398e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: fahrenheit_to_celsius\n",
      "Arguments received: {'fahrenheit': '75'}\n",
      "Function output: 23.88888888888889\n",
      "Final response: To convert Fahrenheit to Celsius, you can use the formula:\n",
      "\n",
      "Celsius = (Fahrenheit - 32) × 5/9\n",
      "\n",
      "Plugging in 75 for Fahrenheit, we get:\n",
      "\n",
      "Celsius = (75 - 32) × 5/9\n",
      "= 43.88888888888889\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "  for tool in response.message.tool_calls:\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print(\"Calling function:\", tool.function.name)\n",
    "      print(\"Arguments received:\", tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print(\"Function output:\", output)\n",
    "    else:\n",
    "      print(\"Function\", tool.function.name, \"not found\")\n",
    "\n",
    "  # Send the tool output(s) back to the LLM for a natural-language answer\n",
    "  messages.append(response.message)                            # original assistant reply\n",
    "  messages.append({                                            # synthetic tool message\n",
    "      \"role\": \"tool\",\n",
    "      \"name\": tool.function.name,\n",
    "      \"content\": str(output)\n",
    "  })\n",
    "  final_response = chat(\"llama3.1\", messages=messages)\n",
    "  print(\"Final response:\", final_response.message.content)\n",
    "\n",
    "else:\n",
    "  print(\"No tool calls returned from model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d37f7-f364-4da2-adf1-03c476dc813f",
   "metadata": {},
   "source": [
    "## Exercise 2: Conversion of Fahrenheit to Celsius -- with a Schema\n",
    "\n",
    "Now it is your turn to try and implement tools for other tasks.\n",
    "The first tools you have to implement are tools to convert Fahrenheit to Celsius (and vice-versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5aa488c-058b-4685-b147-fab8cde4757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Manual JSON-schema description for one of the tools (The other can be passed to `chat` directly, as in the original.)\n",
    "# ----------------------------------------------------------------------\n",
    "celsius_to_fahrenheit_tool = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"celsius_to_fahrenheit\",\n",
    "    \"description\": \"Convert Celsius to Fahrenheit\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"required\": [\"celsius\"],\n",
    "      \"properties\": {\n",
    "        \"celsius\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"Temperature in Celsius\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cee052f-a571-4946-9627-943ff844c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: It's 75°F outside. What is that in Celsius?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"It's 75°F outside. What is that in Celsius?\"\n",
    "  }\n",
    "]\n",
    "\n",
    "print(\"Prompt:\", messages[0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81d5b276-f960-40ff-8197-8e19ac450ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response: ChatResponse = chat(\n",
    "  \"llama3.1\",\n",
    "  messages=messages,\n",
    "  tools=[fahrenheit_to_celsius, celsius_to_fahrenheit_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4527d9d7-cace-4b16-ba58-1f5d6dcb6d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: fahrenheit_to_celsius\n",
      "Arguments received: {'fahrenheit': 75}\n",
      "Function output: 23.88888888888889\n",
      "Final response: To convert 75°F to Celsius, we subtract 32 from the Fahrenheit temperature and then divide by 1.8.\n",
      "\n",
      "75 - 32 = 43\n",
      "43 / 1.8 = 23.889\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# If the model used a tool, run it locally and feed the result back\n",
    "# ----------------------------------------------------------------------\n",
    "if response.message.tool_calls:\n",
    "  for tool in response.message.tool_calls:\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print(\"Calling function:\", tool.function.name)\n",
    "      print(\"Arguments received:\", tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print(\"Function output:\", output)\n",
    "    else:\n",
    "      print(\"Function\", tool.function.name, \"not found\")\n",
    "\n",
    "  # Send the tool output(s) back to the LLM for a natural-language answer\n",
    "  messages.append(response.message)                            # original assistant reply\n",
    "  messages.append({                                            # synthetic tool message\n",
    "      \"role\": \"tool\",\n",
    "      \"name\": tool.function.name,\n",
    "      \"content\": str(output)\n",
    "  })\n",
    "  final_response = chat(\"llama3.1\", messages=messages)\n",
    "  print(\"Final response:\", final_response.message.content)\n",
    "\n",
    "else:\n",
    "  print(\"No tool calls returned from model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf3bd6-76dc-4524-b0bd-3fcf9248f68e",
   "metadata": {},
   "source": [
    "## Exercise 3: Converting strings to Upper and Lower case\n",
    "You are now tasked with implementing tools for converting strings in text to Lower and Upper case (and vice-versa).\n",
    "I.e if the input text is \"hello world\" then the upper case version of this text is \"HELLO WORLD\"\n",
    "I.e if the input text is \"Hello World\" then the lower case version of this text is \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd5a01f9-8b28-4dbb-8286-1242e11cd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_words(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Capitalize every word in a sentence.\n",
    "\n",
    "  Args:\n",
    "    text (str): The input sentence.\n",
    "\n",
    "  Returns:\n",
    "    str: The sentence with each word capitalized.\n",
    "  \"\"\"\n",
    "  # Simple split-and-join to capitalize each word\n",
    "  return \" \".join(word.capitalize() for word in text.split())\n",
    "\n",
    "\n",
    "def lowercase_words(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Convert every character in the sentence to lowercase.\n",
    "  \"\"\"\n",
    "  return text.lower()\n",
    "\n",
    "available_functions = {\n",
    "  'capitalize_words': capitalize_words,\n",
    "  'lowercase_words': lowercase_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be398210-2338-433c-85d1-5ba1f4a301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Please capitalize every word: hello world from ollama\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "  'role': 'user',\n",
    "  'content': 'Please capitalize every word: hello world from ollama',\n",
    "}]\n",
    "print('Prompt:', messages[0]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "924d1b7b-d72f-4179-b2e2-840f87eaf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response: ChatResponse = chat(\n",
    "  'llama3.1',\n",
    "  messages=messages,\n",
    "  tools=[capitalize_words, lowercase_words],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49371531-7718-46fd-859f-4fc7ef576088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: capitalize_words\n",
      "Arguments: {'text': 'hello world from ollama'}\n",
      "Function output: Hello World From Ollama\n",
      "Final response: Here is the corrected response with each word capitalized:\n",
      "\n",
      "Hello World From Ollama\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "  # There may be multiple tool calls in the response\n",
    "  for tool in response.message.tool_calls:\n",
    "    # Ensure the function is available, and then call it\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print('Calling function:', tool.function.name)\n",
    "      print('Arguments:', tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print('Function output:', output)\n",
    "    else:\n",
    "      print('Function', tool.function.name, 'not found')\n",
    "  # Add the function response to messages for the model to use\n",
    "  messages.append(response.message)\n",
    "  messages.append({\n",
    "    'role': 'tool',\n",
    "    'content': str(output),\n",
    "    'name': tool.function.name,\n",
    "  })\n",
    "\n",
    "  # Get final response from model with function outputs\n",
    "  final_response = chat('llama3.1', messages=messages)\n",
    "  print('Final response:', final_response.message.content)\n",
    "\n",
    "else:\n",
    "  print('No tool calls returned from model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8723a-3efe-4468-b6ef-de6e7129e289",
   "metadata": {},
   "source": [
    "## Exercise 4: More Math tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6072c69-1c77-4a93-82ac-686cefca8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_two_numbers(a: float, b: float) -> float:\n",
    "  \"\"\"\n",
    "  Raise one number to the power of another\n",
    "\n",
    "  Args:\n",
    "    a (float): The base\n",
    "    b (float): The exponent\n",
    "\n",
    "  Returns:\n",
    "    float: a raised to the power b\n",
    "  \"\"\"\n",
    "  # Casts ensure the operation is numeric even if the model returns strings\n",
    "  return float(a) ** float(b)\n",
    "\n",
    "def safe_divide(a: float, b: float) -> float:\n",
    "  \"\"\"\n",
    "  Divide two numbers safely (∞ if dividing by zero)\n",
    "\n",
    "  Args:\n",
    "    a (float): The numerator\n",
    "    b (float): The denominator\n",
    "\n",
    "  Returns:\n",
    "    float: a / b, or ∞ if b == 0\n",
    "  \"\"\"\n",
    "  try:\n",
    "    return float(a) / float(b)\n",
    "  except ZeroDivisionError:\n",
    "    return float('inf')\n",
    "\n",
    "# Map of callable tools\n",
    "available_functions = {\n",
    "  'power_two_numbers': power_two_numbers,\n",
    "  'safe_divide': safe_divide,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90becc48-bed6-412d-bdf2-b9de6bbeb9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is five to the power of three?\n"
     ]
    }
   ],
   "source": [
    "# Initial user query\n",
    "messages = [{'role': 'user', 'content': 'What is five to the power of three?'}]\n",
    "print('Prompt:', messages[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "159e341d-e7c5-4fa0-9144-e8aa6dccb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with both tools: one passed as a callable, one as a dict\n",
    "response: ChatResponse = chat(\n",
    "  'llama3.1',\n",
    "  messages=messages,\n",
    "  tools=[power_two_numbers, safe_divide],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1e002c4-4456-41cd-9678-c1eb174bdbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: power_two_numbers\n",
      "Arguments: {'a': 5, 'b': 3}\n",
      "Function output: 125.0\n",
      "Final response: To calculate this, we multiply 5 by itself three times:\n",
      "\n",
      "5 × 5 = 25\n",
      "25 × 5 = 125\n",
      "\n",
      "So, five to the power of three is 125.\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "  for tool in response.message.tool_calls:\n",
    "    if function_to_call := available_functions.get(tool.function.name):\n",
    "      print('Calling function:', tool.function.name)\n",
    "      print('Arguments:', tool.function.arguments)\n",
    "      output = function_to_call(**tool.function.arguments)\n",
    "      print('Function output:', output)\n",
    "    else:\n",
    "      print('Function', tool.function.name, 'not found')\n",
    "\n",
    "  # Provide the tool output back to the model for a natural-language answer\n",
    "  messages.append(response.message)\n",
    "  messages.append({'role': 'tool', 'content': str(output), 'name': tool.function.name})\n",
    "  final_response = chat('llama3.1', messages=messages)\n",
    "  print('Final response:', final_response.message.content)\n",
    "else:\n",
    "  print('No tool calls returned from model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3dbf4-9ecc-4745-914b-d7563cbdb480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
