{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Ollama Features Tutorial üöÄ\n",
    "\n",
    "Welcome to the advanced Ollama tutorial! In this notebook, we'll explore some of the more powerful features of Ollama, including:\n",
    "\n",
    "1. üõ†Ô∏è **Tool Use** - Making AI use custom functions\n",
    "2. üñºÔ∏è **Multimodal Chat** - Talking about images with AI\n",
    "3. üé® **Multimodal Generate** - Creating content based on images\n",
    "4. üìä **Structured Outputs** - Getting organized data from AI\n",
    "5. üñºÔ∏è **Structured Image Analysis** - Getting structured data about images\n",
    "\n",
    "Let's dive into these exciting features! üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup üõ†Ô∏è\n",
    "\n",
    "First, let's install the packages we'll need for this advanced tutorial:\n",
    "- `ollama`: For AI model interactions\n",
    "- `pydantic`: For data validation and structured outputs\n",
    "- `httpx`: For making HTTP requests (used in multimodal examples)\n",
    "\n",
    "Let's install these packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama pydantic httpx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Tool Use: Making AI Use Custom Functions üõ†Ô∏è\n",
    "\n",
    "One of the coolest features of advanced AI models is their ability to use tools - custom functions that we define. This allows the AI to perform actual calculations or actions.\n",
    "\n",
    "In this example, we'll create two simple math functions and let the AI use them to solve problems. Here's how it works:\n",
    "\n",
    "1. We define some functions (tools) that the AI can use\n",
    "2. We tell the AI about these tools\n",
    "3. The AI decides when and how to use them\n",
    "\n",
    "Let's try it out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import ChatResponse, chat\n",
    "\n",
    "# Define our tool functions\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two numbers together\n",
    "    \n",
    "    Args:\n",
    "        a (int): First number\n",
    "        b (int): Second number\n",
    "    \n",
    "    Returns:\n",
    "        int: The sum of the two numbers\n",
    "    \"\"\"\n",
    "    return int(a) + int(b)\n",
    "\n",
    "def subtract_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract the second number from the first\n",
    "    \n",
    "    Args:\n",
    "        a (int): Number to subtract from\n",
    "        b (int): Number to subtract\n",
    "    \n",
    "    Returns:\n",
    "        int: The difference between the numbers\n",
    "    \"\"\"\n",
    "    return int(a) - int(b)\n",
    "\n",
    "# Define the tools in the format Ollama expects\n",
    "subtract_tool = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'subtract_two_numbers',\n",
    "        'description': 'Subtract two numbers',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'required': ['a', 'b'],\n",
    "            'properties': {\n",
    "                'a': {'type': 'integer', 'description': 'The first number'},\n",
    "                'b': {'type': 'integer', 'description': 'The second number'},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create a dictionary of available functions\n",
    "available_functions = {\n",
    "    'add_two_numbers': add_two_numbers,\n",
    "    'subtract_two_numbers': subtract_two_numbers,\n",
    "}\n",
    "\n",
    "# Let's test it with a simple question\n",
    "messages = [{'role': 'user', 'content': 'What is twenty plus five?'}]\n",
    "print('Question:', messages[0]['content'])\n",
    "\n",
    "# Ask the AI and let it use our tools\n",
    "response: ChatResponse = chat(\n",
    "    'llama3.1',\n",
    "    messages=messages,\n",
    "    tools=[add_two_numbers, subtract_tool],\n",
    ")\n",
    "\n",
    "# Handle the AI's response\n",
    "if response.message.tool_calls:\n",
    "    # The AI might make multiple tool calls\n",
    "    for tool in response.message.tool_calls:\n",
    "        if function_to_call := available_functions.get(tool.function.name):\n",
    "            print('\\nAI is using function:', tool.function.name)\n",
    "            print('With arguments:', tool.function.arguments)\n",
    "            result = function_to_call(**tool.function.arguments)\n",
    "            print('Result:', result)\n",
    "            \n",
    "            # Let the AI explain the result\n",
    "            messages.append(response.message)\n",
    "            messages.append({\n",
    "                'role': 'tool', \n",
    "                'content': str(result),\n",
    "                'name': tool.function.name\n",
    "            })\n",
    "            \n",
    "            final_response = chat('llama3.1', messages=messages)\n",
    "            print('\\nAI explains:', final_response.message.content)\n",
    "else:\n",
    "    print('\\nThe AI chose to answer without using any tools:', response.message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Structured Outputs: Getting Organized Data üìä\n",
    "\n",
    "Sometimes we want the AI to give us information in a very specific format. For example, we might want:\n",
    "- A list of items with specific properties\n",
    "- Data that follows a certain structure\n",
    "- Information organized in a particular way\n",
    "\n",
    "We can use Pydantic to define exactly what structure we want. Let's try getting information about some friends in a structured way!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from ollama import chat\n",
    "\n",
    "# Define what information we want about each friend\n",
    "class FriendInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    is_available: bool\n",
    "\n",
    "# Define the structure for a list of friends\n",
    "class FriendList(BaseModel):\n",
    "    friends: list[FriendInfo]\n",
    "\n",
    "# Let's ask about some friends!\n",
    "prompt = \"\"\"\n",
    "I have two friends. \n",
    "The first is Ollama, who is 22 years old and is busy saving the world.\n",
    "The second is Alonso, who is 23 years old and wants to hang out.\n",
    "Return a list of friends in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "# Get structured response from AI\n",
    "response = chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content': prompt}],\n",
    "    format=FriendList.model_json_schema(),  # Tell AI what format we want\n",
    "    options={'temperature': 0}  # Make response more consistent\n",
    ")\n",
    "\n",
    "# Convert the response to our structured format\n",
    "friends_response = FriendList.model_validate_json(response.message.content)\n",
    "\n",
    "# Let's see what we got!\n",
    "print(\"Here's what the AI told us about your friends:\\n\")\n",
    "for friend in friends_response.friends:\n",
    "    status = \"is available\" if friend.is_available else \"is not available\"\n",
    "    print(f\"üßë {friend.name} is {friend.age} years old and {status}\")\n",
    "\n",
    "# We can also see the raw JSON structure\n",
    "print(\"\\nRaw JSON structure:\")\n",
    "print(friends_response.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Multimodal Chat: Talking About Images üñºÔ∏è\n",
    "\n",
    "Now let's try something really cool - talking with AI about images! We can show the AI an image and ask questions about it.\n",
    "\n",
    "For this example, you'll need an image file on your computer. The AI can:\n",
    "- Describe what's in the image\n",
    "- Answer questions about the image\n",
    "- Point out specific details\n",
    "\n",
    "Let's try it out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ollama import chat\n",
    "\n",
    "def chat_about_image(image_path: str, question: str):\n",
    "    \"\"\"\n",
    "    Have a chat with AI about an image\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        question (str): What you want to ask about the image\n",
    "    \"\"\"\n",
    "    # Convert the path to a Path object and check if it exists\n",
    "    path = Path(image_path)\n",
    "    if not path.exists():\n",
    "        return f\"Sorry, couldn't find an image at: {image_path}\"\n",
    "    \n",
    "    try:\n",
    "        # Ask the AI about the image\n",
    "        response = chat(\n",
    "            model='llama3.2-vision',\n",
    "            messages=[{\n",
    "                'role': 'user',\n",
    "                'content': question,\n",
    "                'images': [path]\n",
    "            }]\n",
    "        )\n",
    "        return response.message.content\n",
    "    except Exception as e:\n",
    "        return f\"Oops! Something went wrong: {e}\"\n",
    "\n",
    "# Let's try it out!\n",
    "# You'll need to put in the path to your image\n",
    "image_path = input('Enter the path to your image: ')\n",
    "\n",
    "# Let's ask some questions about the image\n",
    "questions = [\n",
    "    \"What do you see in this image? Be concise.\",\n",
    "    \"What colors are most prominent in this image?\",\n",
    "    \"Is there any text in this image? If so, what does it say?\"\n",
    "]\n",
    "\n",
    "print(\"\\nLet's ask the AI about your image!\\n\")\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    answer = chat_about_image(image_path, question)\n",
    "    print(f\"AI's answer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Structured Image Analysis üñºÔ∏èüìä\n",
    "\n",
    "Now let's combine what we learned about structured outputs with image analysis! We can ask the AI to analyze an image and give us the information in a specific format.\n",
    "\n",
    "We'll create a structure that includes:\n",
    "- A summary of the image\n",
    "- List of objects detected\n",
    "- Scene type\n",
    "- Colors present\n",
    "- Time of day\n",
    "- Setting (Indoor/Outdoor)\n",
    "- Any text found in the image\n",
    "\n",
    "This is super useful when you want to catalog images or analyze them systematically!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from ollama import chat\n",
    "\n",
    "# Define what information we want about objects in the image\n",
    "class Object(BaseModel):\n",
    "    name: str\n",
    "    confidence: float\n",
    "    attributes: str\n",
    "\n",
    "# Define the complete structure for image analysis\n",
    "class ImageDescription(BaseModel):\n",
    "    summary: str\n",
    "    objects: list[Object]\n",
    "    scene: str\n",
    "    colors: list[str]\n",
    "    time_of_day: Literal['Morning', 'Afternoon', 'Evening', 'Night']\n",
    "    setting: Literal['Indoor', 'Outdoor', 'Unknown']\n",
    "    text_content: str | None = None\n",
    "\n",
    "def analyze_image(image_path: str) -> ImageDescription | str:\n",
    "    \"\"\"\n",
    "    Get a structured analysis of an image\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        ImageDescription: Structured analysis of the image\n",
    "        str: Error message if something goes wrong\n",
    "    \"\"\"\n",
    "    path = Path(image_path)\n",
    "    if not path.exists():\n",
    "        return f\"Sorry, couldn't find an image at: {image_path}\"\n",
    "    \n",
    "    try:\n",
    "        # Ask the AI to analyze the image\n",
    "        response = chat(\n",
    "            model='llama3.2-vision',\n",
    "            format=ImageDescription.model_json_schema(),\n",
    "            messages=[{\n",
    "                'role': 'user',\n",
    "                'content': 'Analyze this image and return a detailed JSON description including objects, scene, colors and any text detected. If you cannot determine certain details, leave those fields empty.',\n",
    "                'images': [path]\n",
    "            }],\n",
    "            options={'temperature': 0}\n",
    "        )\n",
    "        \n",
    "        # Convert the response to our structured format\n",
    "        return ImageDescription.model_validate_json(response.message.content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Oops! Something went wrong: {e}\"\n",
    "\n",
    "# Let's analyze an image!\n",
    "image_path = input('Enter the path to your image: ')\n",
    "analysis = analyze_image(image_path)\n",
    "\n",
    "if isinstance(analysis, ImageDescription):\n",
    "    print(\"\\nüì∏ Image Analysis Results:\\n\")\n",
    "    print(f\"Summary: {analysis.summary}\\n\")\n",
    "    \n",
    "    print(\"Objects Detected:\")\n",
    "    for obj in analysis.objects:\n",
    "        print(f\"- {obj.name} (Confidence: {obj.confidence:.2f})\")\n",
    "        print(f\"  Attributes: {obj.attributes}\")\n",
    "    \n",
    "    print(f\"\\nScene: {analysis.scene}\")\n",
    "    print(f\"Colors: {', '.join(analysis.colors)}\")\n",
    "    print(f\"Time of Day: {analysis.time_of_day}\")\n",
    "    print(f\"Setting: {analysis.setting}\")\n",
    "    \n",
    "    if analysis.text_content:\n",
    "        print(f\"\\nText Detected: {analysis.text_content}\")\n",
    "else:\n",
    "    print(f\"Error: {analysis}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Multimodal Generate: Fun with Comics! üé®\n",
    "\n",
    "For our final example, let's do something fun - we'll analyze XKCD comics! This example shows how to:\n",
    "- Fetch images from the web\n",
    "- Use AI to understand and explain comics\n",
    "- Stream the AI's response in real-time\n",
    "\n",
    "This is a great example of combining web requests, image analysis, and streaming responses!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import httpx\n",
    "from ollama import generate\n",
    "\n",
    "def explain_xkcd_comic(comic_number: int | None = None):\n",
    "    \"\"\"\n",
    "    Fetch and explain an XKCD comic\n",
    "    \n",
    "    Args:\n",
    "        comic_number: Optional specific comic number to explain\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the latest comic info\n",
    "        latest = httpx.get('https://xkcd.com/info.0.json')\n",
    "        latest.raise_for_status()\n",
    "        \n",
    "        # Pick a random comic if none specified\n",
    "        num = comic_number if comic_number else random.randint(1, latest.json().get('num'))\n",
    "        \n",
    "        # Get the comic info\n",
    "        comic = httpx.get(f'https://xkcd.com/{num}/info.0.json')\n",
    "        comic.raise_for_status()\n",
    "        comic_data = comic.json()\n",
    "        \n",
    "        print(f\"XKCD #{comic_data.get('num')}: {comic_data.get('alt')}\")\n",
    "        print(f\"Link: https://xkcd.com/{num}\")\n",
    "        print(\"---\")\n",
    "        \n",
    "        # Get the image\n",
    "        image = httpx.get(comic_data.get('img'))\n",
    "        image.raise_for_status()\n",
    "        \n",
    "        # Have the AI explain the comic, streaming the response\n",
    "        print(\"AI's explanation:\")\n",
    "        for response in generate(\n",
    "            'llava',\n",
    "            'explain this comic:',\n",
    "            images=[image.content],\n",
    "            stream=True\n",
    "        ):\n",
    "            print(response['response'], end='', flush=True)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Oops! Something went wrong: {e}\")\n",
    "\n",
    "# Let's try it with a random comic!\n",
    "explain_xkcd_comic()\n",
    "\n",
    "# You can also try a specific comic number:\n",
    "# explain_xkcd_comic(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Wrapping Up üéâ\n",
    "\n",
    "Congratulations! You've learned about some really powerful features of Ollama:\n",
    "\n",
    "1. üõ†Ô∏è **Tool Use**: Making AI use custom functions to perform real actions\n",
    "2. üìä **Structured Outputs**: Getting organized, validated data from AI\n",
    "3. üñºÔ∏è **Multimodal Chat**: Having conversations about images\n",
    "4. üì∏ **Structured Image Analysis**: Getting detailed, organized information about images\n",
    "5. üé® **Multimodal Generate**: Working with images and streaming responses\n",
    "\n",
    "Things to try next:\n",
    "- Create your own tools for the AI to use\n",
    "- Define different structures for the data you want\n",
    "- Try analyzing different types of images\n",
    "- Combine these features in creative ways!\n",
    "\n",
    "Remember:\n",
    "- Always check if the AI model you want to use is available (`llama3.2-vision` for images)\n",
    "- Handle errors gracefully as network or model issues can occur\n",
    "- Save interesting results for later reference\n",
    "\n",
    "Have fun exploring these advanced features! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
